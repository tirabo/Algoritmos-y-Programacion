{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4cEbRnEIl8p"
      },
      "source": [
        "# Interacción con archivos CSV, XML y JSON\n",
        "\n",
        "Es común que cuando interactuamos y obtenemos datos de páginas o sitios de Internet estos datos se encuentren en formatos estructurados. Veremos a continuación, brevemente, como podemos obtener datos de archivos CSV, XML y JSON."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Archivos CSV\n",
        "\n",
        "La forma estructurada más sencilla de información es un archivo CSV,  que es similar a una hoja de una planilla de cálculo.\n",
        "\n",
        "Un archivo CSV (Comma Separated Values) es un tipo de archivo de texto que se utiliza comúnmente para almacenar datos tabulares. Los datos en un archivo CSV se organizan en filas y columnas, donde cada fila corresponde a un registro y cada columna corresponde a un campo en ese registro. Los campos en un archivo CSV se separan por un carácter delimitador, como una coma, un punto y coma o una tabulación.\n",
        "\n",
        "Cada registro en un archivo CSV se almacena en una nueva línea, y los valores de los campos pueden estar rodeados de comillas dobles si contienen el carácter delimitador. Por ejemplo, el siguiente es un ejemplo de un archivo CSV que contiene información sobre personas:\n",
        "\n",
        "    nombre,edad,ciudad\n",
        "    Juan,30,Quito\n",
        "    María,25,Medellín\n",
        "    Pedro,40,Lima\n",
        "\n",
        "En este ejemplo, la primera línea del archivo CSV contiene los nombres de los campos (`nombre`, `edad` y `ciudad`), mientras que las siguientes líneas contienen los datos de los registros.\n",
        "\n",
        "Los archivos CSV son una forma común de intercambiar datos entre diferentes programas o sistemas, ya que son un formato simple y legible por humanos. También se pueden abrir y editar fácilmente en programas de hojas de cálculo, como Microsoft Excel o Google Sheets.\n",
        "\n",
        "Por otro lado,  tiene la limitación de que la información se puede estructurar unicamente en filas y columnas.\n"
      ],
      "metadata": {
        "id": "UckRYiOYDsCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construyamos un ejemplo sencillo:"
      ],
      "metadata": {
        "id": "3ne8JSYyjoB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('archivo.csv', 'w') as csvfile:\n",
        "    csvfile.write('nombre, edad,ciudad\\n')\n",
        "    csvfile.write('\"Perez,Juan\", 30, Quito\\n')\n",
        "    csvfile.write('María, 25, Medellín\\n')\n",
        "    csvfile.write('Pedro, 40, Lima\\n')"
      ],
      "metadata": {
        "id": "2vZCzMsGjr2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para leer un archivo CSV en Python, puede utilizar el módulo `csv`. Este módulo proporciona una forma fácil de leer y escribir archivos CSV. A continuación, se muestra un ejemplo de cómo leer un archivo CSV y obtener los valores de los campos:\n",
        "\n",
        "Usaremos un archivo CSV  que nos provee Colab. Leamos el archivo `california_housing_test.csv`  con el siguiente contenido:\n",
        "\n",
        "    longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value\n",
        "    -122.050000,37.370000,27.000000,3885.000000,661.000000,1537.000000,606.000000,6.608500,344700.000000\n",
        "    -118.300000,34.260000,43.000000,1510.000000,310.000000,809.000000,277.000000,3.599000,176500.000000\n",
        "    -117.810000,33.780000,27.000000,3589.000000,507.000000,1484.000000,495.000000,5.793400,270500.000000\n",
        "    ...\n",
        "\n",
        "Para leer este archivo, se puede usar el siguiente código en Python:"
      ],
      "metadata": {
        "id": "FKuaoouZEk8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# abre el archivo CSV en modo lectura\n",
        "with open('/content/sample_data/california_housing_test.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"') # crea un objeto reader de CSV\n",
        "    valores = []\n",
        "    # iteramos sobre las filas del archivo CSV:\n",
        "    for fila in reader:\n",
        "        valores.append(fila)\n",
        "\n",
        "# imprime algunos valores de las primera filas\n",
        "print(\"El tipo de cada fila es:\", type(valores[0]))\n",
        "print(\"La cantidad de campos es:\", len(valores[0]))\n",
        "for i in range(10):\n",
        "    fila = valores[i]\n",
        "    print(fila[0], fila[1], fila[2])\n"
      ],
      "metadata": {
        "id": "7T1px3ZRGIYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad1db9c-61b0-4852-c151-ce102cdaa4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El tipo de cada fila es: <class 'list'>\n",
            "La cantidad de campos es: 9\n",
            "longitude latitude housing_median_age\n",
            "-122.050000 37.370000 27.000000\n",
            "-118.300000 34.260000 43.000000\n",
            "-117.810000 33.780000 27.000000\n",
            "-118.360000 33.820000 28.000000\n",
            "-119.670000 36.330000 19.000000\n",
            "-119.560000 36.510000 37.000000\n",
            "-121.430000 38.630000 43.000000\n",
            "-120.650000 35.480000 19.000000\n",
            "-122.840000 38.400000 15.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este código, usamos la función `open()` para abrir el archivo CSV en modo lectura. A continuación, creamos un objeto lector de CSV usando la función `csv.reader()`. Este objeto lector toma el archivo CSV y los parámetros `delimiter` y `quotechar`, que indican el carácter delimitador y el carácter de comillas, respectivamente. En este ejemplo, estamos usando comas como delimitadores y comillas dobles como caracteres de comillas.\n",
        "\n",
        "Luego, iteramos sobre las filas del archivo CSV utilizando un ciclo `for`. Guardamos las filas del archivo CSV  en la lista `valores` y  luego imprimimos algunos valores de las primeras filas.\n",
        "\n",
        "En resumen, para leer un archivo CSV en Python, puede usar el módulo `csv` y la función `csv.reader()`. Para obtener los valores de los campos, simplemente iteramos sobre el objeto `reader`.\n",
        "\n",
        "También podríamos haber hecho `valores = list(reader)` e iteramos sobre la lista."
      ],
      "metadata": {
        "id": "dHD-xHQkFk7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente,  como la primera fila son los id de los campos, no son valores que nos interesan. Una forma eficiente de leer solo los valores es la siguiente:"
      ],
      "metadata": {
        "id": "M-ZrLUs4rNWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/california_housing_test.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"') # crea un objeto reader de CSV\n",
        "    next(reader) # salta la primera fila\n",
        "    valores = []\n",
        "    for fila in reader:\n",
        "        valores.append(fila)"
      ],
      "metadata": {
        "id": "SHVP0bTTre0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UiG9ZcuIl9A"
      },
      "source": [
        "## 2. Lectura y escritura de archivos JSON\n",
        "\n",
        "JSON, cuyo nombre corresponde a las siglas *JavaScript Object Notation* o *Notación de Objetos de JavaScript*, es un formato ligero de intercambio de datos, que resulta sencillo de leer y escribir para los programadores y simple de interpretar y generar para las máquinas.\n",
        "\n",
        "JSON es un formato de texto completamente independiente de lenguaje y puede ser interpretado y creado por los siguientes lenguajes:\n",
        "\n",
        "- C\n",
        "- C++\n",
        "- C#\n",
        "- Java\n",
        "- JavaScript\n",
        "- Perl\n",
        "- Python\n",
        "- etc.\n",
        "\n",
        "Muchos lenguajes de programación proporcionan métodos para analizar una cadena de texto con este formato en un objeto nativo y viceversa.\n",
        "\n",
        "Pese a su nombre, no es necesariamente parte de JavaScript, de hecho, es un estándar basado en texto plano para el intercambio de datos, por lo que se usa en muchos sistemas que requieren mostrar o enviar información para ser interpretada por otros sistemas.\n",
        "\n",
        "Una de las características de JSON, al ser un formato que es independiente de cualquier lenguaje de programación, es que los servicios que comparten información por este método no necesitan hablar el mismo idioma, es decir, el emisor puede ser Java y el receptor Python, pues cada uno tiene su propia librería para codificar y decodificar cadenas en este formato.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFjbOX9dhqWt"
      },
      "source": [
        "Veamos como leer y escribir archivos json:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIUb-MzXIl9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75ff8c2-27a1-4933-a158-187442f82f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo del archivo: <class 'list'>\n",
            "Tipo de cada elemento del archivo: <class 'dict'>\n",
            "\n",
            "Imprimimos todo el archivo:\n",
            "[{'Series': 'I', 'X': 10.0, 'Y': 8.04}, {'Series': 'I', 'X': 8.0, 'Y': 6.95}, {'Series': 'I', 'X': 13.0, 'Y': 7.58}, {'Series': 'I', 'X': 9.0, 'Y': 8.81}, {'Series': 'I', 'X': 11.0, 'Y': 8.33}, {'Series': 'I', 'X': 14.0, 'Y': 9.96}, {'Series': 'I', 'X': 6.0, 'Y': 7.24}, {'Series': 'I', 'X': 4.0, 'Y': 4.26}, {'Series': 'I', 'X': 12.0, 'Y': 10.84}, {'Series': 'I', 'X': 7.0, 'Y': 4.81}, {'Series': 'I', 'X': 5.0, 'Y': 5.68}, {'Series': 'II', 'X': 10.0, 'Y': 9.14}, {'Series': 'II', 'X': 8.0, 'Y': 8.14}, {'Series': 'II', 'X': 13.0, 'Y': 8.74}, {'Series': 'II', 'X': 9.0, 'Y': 8.77}, {'Series': 'II', 'X': 11.0, 'Y': 9.26}, {'Series': 'II', 'X': 14.0, 'Y': 8.1}, {'Series': 'II', 'X': 6.0, 'Y': 6.13}, {'Series': 'II', 'X': 4.0, 'Y': 3.1}, {'Series': 'II', 'X': 12.0, 'Y': 9.13}, {'Series': 'II', 'X': 7.0, 'Y': 7.26}, {'Series': 'II', 'X': 5.0, 'Y': 4.74}, {'Series': 'III', 'X': 10.0, 'Y': 7.46}, {'Series': 'III', 'X': 8.0, 'Y': 6.77}, {'Series': 'III', 'X': 13.0, 'Y': 12.74}, {'Series': 'III', 'X': 9.0, 'Y': 7.11}, {'Series': 'III', 'X': 11.0, 'Y': 7.81}, {'Series': 'III', 'X': 14.0, 'Y': 8.84}, {'Series': 'III', 'X': 6.0, 'Y': 6.08}, {'Series': 'III', 'X': 4.0, 'Y': 5.39}, {'Series': 'III', 'X': 12.0, 'Y': 8.15}, {'Series': 'III', 'X': 7.0, 'Y': 6.42}, {'Series': 'III', 'X': 5.0, 'Y': 5.73}, {'Series': 'IV', 'X': 8.0, 'Y': 6.58}, {'Series': 'IV', 'X': 8.0, 'Y': 5.76}, {'Series': 'IV', 'X': 8.0, 'Y': 7.71}, {'Series': 'IV', 'X': 8.0, 'Y': 8.84}, {'Series': 'IV', 'X': 8.0, 'Y': 8.47}, {'Series': 'IV', 'X': 8.0, 'Y': 7.04}, {'Series': 'IV', 'X': 8.0, 'Y': 5.25}, {'Series': 'IV', 'X': 19.0, 'Y': 12.5}, {'Series': 'IV', 'X': 8.0, 'Y': 5.56}, {'Series': 'IV', 'X': 8.0, 'Y': 7.91}, {'Series': 'IV', 'X': 8.0, 'Y': 6.89}]\n",
            "\n",
            "Imprimimos alguna información del archivo:\n",
            "10.0\n",
            "8.0\n",
            "13.0\n",
            "9.0\n",
            "11.0\n",
            "14.0\n",
            "6.0\n",
            "4.0\n",
            "12.0\n",
            "7.0\n",
            "5.0\n",
            "10.0\n",
            "8.0\n",
            "13.0\n",
            "9.0\n",
            "11.0\n",
            "14.0\n",
            "6.0\n",
            "4.0\n",
            "12.0\n",
            "7.0\n",
            "5.0\n",
            "10.0\n",
            "8.0\n",
            "13.0\n",
            "9.0\n",
            "11.0\n",
            "14.0\n",
            "6.0\n",
            "4.0\n",
            "12.0\n",
            "7.0\n",
            "5.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n",
            "19.0\n",
            "8.0\n",
            "8.0\n",
            "8.0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('./sample_data/anscombe.json', 'r') as f:\n",
        "    data = f.read() # data es una str\n",
        "\n",
        "archivo = json.loads(data) # archivo es (en este caso) una lista de diccionarios\n",
        "print('Tipo del archivo:', type(archivo))\n",
        "print('Tipo de cada elemento del archivo:',type(archivo[0]))\n",
        "\n",
        "print('\\nImprimimos todo el archivo:')\n",
        "print(archivo)\n",
        "\n",
        "print('\\nImprimimos alguna información del archivo:')\n",
        "for item in archivo:\n",
        "    print(item['X'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bU2MV2eIl9B"
      },
      "source": [
        "Lo notable de JSON  es que los archivos de texto en formato JSON son muy parecidos a los diccionarios y listas de Python,  con una sintaxis idéntica.\n",
        "\n",
        "La operación inversa a `json.loads()` es `json.dumps()`:  transforma un diccionario o lista en una cadena con  estructura JSON.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK5D4Fow3yEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f00ea07a-33f3-4c13-cb75-76c6af69e48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Un diccionario:\t\t\t <class 'dict'> {'a': {2: 0}, 'b': {1: 5}}\n",
            "Un JSON:\t\t\t <class 'str'> {\"a\": {\"2\": 0}, \"b\": {\"1\": 5}}\n",
            "De nuevo un diccionario:\t <class 'dict'> {'a': {'2': 0}, 'b': {'1': 5}}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "u = {'a': {2 : 0 }, 'b': {1 : 5 }} # u es un diccionario\n",
        "print ('Un diccionario:\\t\\t\\t',type(u), u)\n",
        "x = json.dumps({'a': {2 : 0 }, 'b': {1 : 5 }}) # transforma a JSON (es una str)\n",
        "print('Un JSON:\\t\\t\\t', type(x), x)\n",
        "y = json.loads(x)\n",
        "print('De nuevo un diccionario:\\t',type(y), y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar que el diccionario original cambia las claves numérica de *TODOS* los diccionarios a tipo `str`, incluso los diccionarios que son valores de otro diccionario.\n",
        "\n",
        "Los valores numéricos se mantienen numéricos. Si un valor es un lista,  se mantiene lista."
      ],
      "metadata": {
        "id": "_WuMNEtuLYfu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jli-TtyZ3zPw"
      },
      "source": [
        "**Ejemplo.** Crearemos una lista de diccionarios y queremos escribir uno por línea en un archivo, para que luego sea leido usando `json.loads()`.\n",
        "\n",
        "En  la celda de código siguiente implementamos un ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYbT-pj5xCwC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# Creamos una lista con 100 diccionarios tipo\n",
        "# {'x' : entero al azar, 'y' : entero al azar, nº de orden en la lista : [entero al azar, entero al azar] }\n",
        "# Los guardaremos en el archivo prueba.txt, uno en cada linea.\n",
        "\n",
        "lista_dic = []\n",
        "for i in range(100):\n",
        "  x, y, w0, w1 = random.randint(1, 1000), random.randint(1, 1000), random.randint(1, 1000), random.randint(1, 1000)\n",
        "  lista_dic.append({ 'x' : x, 'y' : y, i : [w0 , w1]})\n",
        "\n",
        "# Guardamos en el archivo prueba.txt, línea por línea el diccionario.\n",
        "\n",
        "with open('prueba.txt', 'w') as f:\n",
        "    for i in range(len(lista_dic)):\n",
        "        f.write(json.dumps(lista_dic[i])+'\\n') # \\n pasa de renglón\n",
        "\n",
        "# Revisar el archivo prueba.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para leer debemos hacerlo también linea por linea, pues el archivo\n",
        "# no tiene la estructura lógica de un diccionario o lista\n",
        "# (debería abrir con { o [ y cerrar con } o  ],  respectivamente)\n",
        "\n",
        "# Ahora haremos una lista de diccionarios a partir de prueba.txt\n",
        "\n",
        "lista_dic2 = []\n",
        "with open('prueba.txt', 'r') as f:\n",
        "    for linea in f:\n",
        "        lista_dic2.append(json.loads(linea))\n",
        "\n",
        "print(lista_dic2)\n",
        "\n",
        "print(type(lista_dic2[3]), lista_dic2[3]) # comprobamos que cada coordenada\n",
        "# es un diccionario\n",
        "\n",
        "# Importante:  las claves numéricas pasaron a str. Los valores matienen su tipo (int, list, etc)\n",
        "print(lista_dic[3][3])\n",
        "print(lista_dic2[3]['3']) # No estaría bien  print(lista_dic2[3][3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_k_1cpJxBSo",
        "outputId": "2fa74e1c-07a2-49ba-b0c2-7107a0ef6f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'x': 234, 'y': 642, '0': [18, 237]}, {'x': 137, 'y': 478, '1': [2, 583]}, {'x': 466, 'y': 514, '2': [219, 426]}, {'x': 112, 'y': 435, '3': [284, 711]}, {'x': 227, 'y': 693, '4': [407, 188]}, {'x': 570, 'y': 730, '5': [305, 798]}, {'x': 789, 'y': 918, '6': [455, 32]}, {'x': 944, 'y': 314, '7': [338, 265]}, {'x': 407, 'y': 727, '8': [548, 152]}, {'x': 598, 'y': 880, '9': [429, 952]}, {'x': 232, 'y': 660, '10': [43, 554]}, {'x': 689, 'y': 184, '11': [471, 730]}, {'x': 585, 'y': 514, '12': [63, 90]}, {'x': 693, 'y': 760, '13': [419, 141]}, {'x': 562, 'y': 97, '14': [46, 70]}, {'x': 976, 'y': 95, '15': [763, 308]}, {'x': 759, 'y': 245, '16': [29, 656]}, {'x': 890, 'y': 830, '17': [70, 445]}, {'x': 425, 'y': 66, '18': [321, 270]}, {'x': 544, 'y': 281, '19': [14, 791]}, {'x': 390, 'y': 548, '20': [58, 404]}, {'x': 985, 'y': 392, '21': [274, 57]}, {'x': 989, 'y': 59, '22': [791, 470]}, {'x': 432, 'y': 961, '23': [870, 919]}, {'x': 99, 'y': 545, '24': [387, 691]}, {'x': 409, 'y': 56, '25': [656, 265]}, {'x': 65, 'y': 628, '26': [773, 188]}, {'x': 553, 'y': 639, '27': [270, 518]}, {'x': 504, 'y': 631, '28': [719, 405]}, {'x': 124, 'y': 897, '29': [470, 352]}, {'x': 996, 'y': 443, '30': [195, 266]}, {'x': 585, 'y': 579, '31': [731, 987]}, {'x': 869, 'y': 689, '32': [735, 458]}, {'x': 77, 'y': 293, '33': [483, 910]}, {'x': 760, 'y': 813, '34': [415, 270]}, {'x': 681, 'y': 977, '35': [177, 843]}, {'x': 676, 'y': 894, '36': [934, 942]}, {'x': 37, 'y': 814, '37': [174, 141]}, {'x': 309, 'y': 115, '38': [563, 940]}, {'x': 924, 'y': 152, '39': [100, 627]}, {'x': 339, 'y': 231, '40': [606, 157]}, {'x': 487, 'y': 315, '41': [558, 771]}, {'x': 980, 'y': 753, '42': [434, 108]}, {'x': 734, 'y': 583, '43': [247, 996]}, {'x': 120, 'y': 173, '44': [421, 6]}, {'x': 502, 'y': 820, '45': [220, 750]}, {'x': 433, 'y': 241, '46': [402, 234]}, {'x': 39, 'y': 371, '47': [201, 197]}, {'x': 378, 'y': 387, '48': [342, 217]}, {'x': 544, 'y': 770, '49': [458, 138]}, {'x': 423, 'y': 721, '50': [35, 524]}, {'x': 208, 'y': 564, '51': [11, 830]}, {'x': 117, 'y': 626, '52': [335, 951]}, {'x': 39, 'y': 972, '53': [947, 314]}, {'x': 802, 'y': 592, '54': [354, 237]}, {'x': 630, 'y': 156, '55': [330, 68]}, {'x': 102, 'y': 211, '56': [713, 156]}, {'x': 834, 'y': 297, '57': [235, 117]}, {'x': 986, 'y': 278, '58': [842, 943]}, {'x': 691, 'y': 877, '59': [819, 248]}, {'x': 629, 'y': 707, '60': [952, 488]}, {'x': 103, 'y': 987, '61': [592, 622]}, {'x': 574, 'y': 527, '62': [918, 592]}, {'x': 339, 'y': 46, '63': [996, 155]}, {'x': 525, 'y': 710, '64': [621, 751]}, {'x': 300, 'y': 661, '65': [346, 967]}, {'x': 373, 'y': 833, '66': [738, 559]}, {'x': 542, 'y': 329, '67': [516, 438]}, {'x': 775, 'y': 832, '68': [928, 134]}, {'x': 888, 'y': 110, '69': [42, 527]}, {'x': 73, 'y': 379, '70': [946, 602]}, {'x': 630, 'y': 109, '71': [13, 882]}, {'x': 233, 'y': 216, '72': [970, 681]}, {'x': 538, 'y': 439, '73': [557, 826]}, {'x': 235, 'y': 359, '74': [319, 338]}, {'x': 343, 'y': 632, '75': [795, 480]}, {'x': 25, 'y': 17, '76': [522, 142]}, {'x': 200, 'y': 549, '77': [401, 95]}, {'x': 489, 'y': 421, '78': [541, 941]}, {'x': 967, 'y': 557, '79': [906, 328]}, {'x': 212, 'y': 961, '80': [895, 45]}, {'x': 693, 'y': 588, '81': [226, 885]}, {'x': 567, 'y': 807, '82': [140, 700]}, {'x': 442, 'y': 366, '83': [183, 826]}, {'x': 351, 'y': 544, '84': [167, 133]}, {'x': 102, 'y': 156, '85': [640, 979]}, {'x': 840, 'y': 438, '86': [737, 347]}, {'x': 6, 'y': 962, '87': [358, 290]}, {'x': 377, 'y': 922, '88': [25, 732]}, {'x': 221, 'y': 592, '89': [987, 683]}, {'x': 629, 'y': 190, '90': [27, 126]}, {'x': 267, 'y': 400, '91': [399, 497]}, {'x': 35, 'y': 208, '92': [218, 696]}, {'x': 59, 'y': 333, '93': [356, 206]}, {'x': 823, 'y': 648, '94': [215, 42]}, {'x': 52, 'y': 930, '95': [203, 670]}, {'x': 25, 'y': 451, '96': [646, 158]}, {'x': 985, 'y': 374, '97': [763, 970]}, {'x': 554, 'y': 990, '98': [700, 528]}, {'x': 864, 'y': 827, '99': [487, 520]}]\n",
            "<class 'dict'> {'x': 112, 'y': 435, '3': [284, 711]}\n",
            "[284, 711]\n",
            "[284, 711]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEYYnfh_UMud"
      },
      "source": [
        "*Ejemplos de cosas que  **NO** funcionan.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CkqukDhUaqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d428a9-2d13-4b94-ab5b-9f33b8ca3709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'> \"{'a': {2 : 0 }, 'b': {1 : 5 }}\"\n",
            "<class 'str'> {'a': {2 : 0 }, 'b': {1 : 5 }}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# Si hacemos json.dumps()  de una string, Python lo hace, pero no es el resultado que esperamos.\n",
        "x = json.dumps(\"{'a': {2 : 0 }, 'b': {1 : 5 }}\")\n",
        "print(type(x), x)\n",
        "y = json.loads(x)\n",
        "print(type(y), y) # json.loads() en este caso devuelve una string!\n",
        "# y es una string que \"parece\" un diccionario. Pero no lo es.\n",
        "# z = json.loads(y) #  esto directamente da error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZOXLKbUV_d-"
      },
      "source": [
        "**Recomendación:** Usar `json.loads()` y `json.dumps()` de forma prolija y de acuerdo a los lineamientos escritos más arriba. Quizás haciendo aguna  \"magia\" con los `replace()` se pueda arreglar la celda de código anterior, pero es mejor no hacerlo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Lectura de archivos JSON en internet\n",
        "\n",
        "\n",
        "Para leer un archivo JSON desde internet utilizando el módulo `requests` en Python, se puede hacer lo siguiente:\n",
        "\n",
        "    import requests\n",
        "\n",
        "Hcemos una solicitud HTTP GET al servidor que contiene el archivo JSON utilizando la función `get()` de `requests`. La respuesta de la solicitud será un objeto `Response` que contiene la información de la respuesta del servidor.\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "Donde `url` es la dirección URL del archivo JSON que deseamos leer.\n",
        "\n",
        "Verificamos que la solicitud se haya realizado correctamente en base al código de estado de la respuesta. Si el código de estado es `200`, significa que la solicitud se realizó correctamente.\n",
        "\n",
        "Si la solicitud se realizó correctamente, puedes acceder al contenido del archivo JSON utilizando el método `json()` del objeto `Response`. Este método decodifica el contenido JSON y devuelve un objeto Python que representa los datos del archivo JSON.\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # El archivo JSON fue encontrado y cargado correctamente\n",
        "        data = response.json()\n",
        "    else:\n",
        "        print('Hubo un problema al cargar el archivo JSON')\n",
        "\n",
        "El objeto data ahora contiene los datos del archivo JSON, los cuales podemos utilizar en tu programa como cualquier otro objeto Python."
      ],
      "metadata": {
        "id": "th0uqz31ksd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo.** Leeremos un archivo de internet con los siguientes datos:  \n",
        "\n",
        "    {\"catalog\":\n",
        "        {\"book\":\n",
        "        [\n",
        "            {\"@id\": \"bk101\",\n",
        "                \"author\": [\"Gambardella, Matthew\"],\n",
        "                \"title\": \"XML Developer's Guide\",\n",
        "                \"genre\": \"Computer\",\n",
        "                \"price\": \"44.95\",\n",
        "                \"publish_date\": \"2000-10-01\",\n",
        "                \"description\": \"An in-depth look at creating applications with XML.\"},\n",
        "            {\"@id\": \"bk102\",\n",
        "                \"author\": [\"Ralls, Kim\", \"Gambardella, Matthew\"],\n",
        "                \"title\": \"Midnight Rain\",\n",
        "                \"genre\": \"Fantasy\",\n",
        "                \"price\": \"5.95\",\n",
        "                \"publish_date\": \"2000-12-16\",\n",
        "                \"description\": \"A former architect battles ...\"},\n",
        "            ...\n",
        "            ...\n",
        "        ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "El archivo completo se encuentra en\n",
        "\n",
        "    https://raw.githubusercontent.com/tirabo/Algoritmos-y-Programacion/main/2023/archivos/books.json\n",
        "\n",
        "Leamos el archivo:"
      ],
      "metadata": {
        "id": "zZKCZEJD4LKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/tirabo/Algoritmos-y-Programacion/main/2023/archivos/books.json'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    # El archivo JSON fue encontrado y cargado correctamente\n",
        "    data = response.json()\n",
        "else:\n",
        "    print('Hubo un problema al cargar el archivo JSON')\n",
        "print(response.status_code)"
      ],
      "metadata": {
        "id": "WbroI5v_4nyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a26d527-8a94-4aea-da8a-8fd4f7f29ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimamos su contenido:"
      ],
      "metadata": {
        "id": "z6nbydq9482o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))\n",
        "print(data)"
      ],
      "metadata": {
        "id": "-b-yzKC05Bzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6552b120-7179-4b75-914d-6cfe89567e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'catalog': {'book': [{'@id': 'bk101', 'author': ['Gambardella, Matthew'], 'title': \"XML Developer's Guide\", 'genre': 'Computer', 'price': '44.95', 'publish_date': '2000-10-01', 'description': 'An in-depth look at creating applications with XML.'}, {'@id': 'bk102', 'author': ['Ralls, Kim', 'Gambardella, Matthew'], 'title': 'Midnight Rain', 'genre': 'Fantasy', 'price': '5.95', 'publish_date': '2000-12-16', 'description': 'A former architect battles corporate zombies, an evil sorceress, and her own childhood to become queen of the world.'}, {'@id': 'bk103', 'author': ['Corets, Eva'], 'title': 'Maeve Ascendant', 'genre': 'Fantasy', 'price': '5.95', 'publish_date': '2000-11-17', 'description': 'After the collapse of a nanotechnology society in England, the young survivors lay the foundation for a new society.'}, {'@id': 'bk104', 'author': ['Corets, Eva'], 'title': \"Oberon's Legacy\", 'genre': 'Fantasy', 'price': '5.95', 'publish_date': '2001-03-10', 'description': 'In post-apocalypse England, the mysterious agent known only as Oberon helps to create a new life for the inhabitants of London. Sequel to Maeve Ascendant.'}, {'@id': 'bk105', 'author': ['Corets, Eva'], 'title': 'The Sundered Grail', 'genre': 'Fantasy', 'price': '5.95', 'publish_date': '2001-09-10', 'description': \"The two daughters of Maeve, half-sisters, battle one another for control of England. Sequel to Oberon's Legacy.\"}, {'@id': 'bk106', 'author': ['Randall, Cynthia'], 'title': 'Lover Birds', 'genre': 'Romance', 'price': '4.95', 'publish_date': '2000-09-02', 'description': 'When Carla meets Paul at an ornithology conference, tempers fly as feathers get ruffled.'}, {'@id': 'bk107', 'author': ['Thurman, Paula'], 'title': 'Splish Splash', 'genre': 'Romance', 'price': '4.95', 'publish_date': '2000-11-02', 'description': 'A deep sea diver finds true love twenty thousand leagues beneath the sea.'}, {'@id': 'bk108', 'author': ['Knorr, Stefan'], 'title': 'Creepy Crawlies', 'genre': 'Horror', 'price': '4.95', 'publish_date': '2000-12-06', 'description': 'An anthology of horror stories about roaches, centipedes, scorpions  and other insects.'}, {'@id': 'bk109', 'author': ['Kress, Peter'], 'title': 'Paradox Lost', 'genre': 'Science Fiction', 'price': '6.95', 'publish_date': '2000-11-02', 'description': 'After an inadvertant trip through a Heisenberg Uncertainty Device, James Salway discovers the problems of being quantum.'}, {'@id': 'bk110', 'author': [\"O'Brien, Tim\"], 'title': 'Microsoft .NET: The Programming Bible', 'genre': 'Computer', 'price': '36.95', 'publish_date': '2000-12-09', 'description': \"Microsoft's .NET initiative is explored in detail in this deep programmer's reference.\"}, {'@id': 'bk111', 'author': [\"O'Brien, Tim\"], 'title': 'MSXML3: A Comprehensive Guide', 'genre': 'Computer', 'price': '36.95', 'publish_date': '2000-12-01', 'description': 'The Microsoft MSXML3 parser is covered in detail, with attention to XML DOM interfaces, XSLT processing, SAX and more.'}, {'@id': 'bk112', 'author': ['Galos, Mike'], 'title': 'Visual Studio 7: A Comprehensive Guide', 'genre': 'Computer', 'price': '49.95', 'publish_date': '2001-04-16', 'description': 'Microsoft Visual Studio 7 is explored in depth, looking at how Visual Basic, Visual C++, C#, and ASP+ are integrated into a comprehensive development environment.'}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego si deseamos obtener metadatos del primer libro podemos hacer:"
      ],
      "metadata": {
        "id": "UbyCi_zl5PxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['catalog']['book'][0]"
      ],
      "metadata": {
        "id": "cVu2U0rj5WAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea32a41-37c9-4525-a047-1aa2699c6e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'@id': 'bk101',\n",
              " 'author': ['Gambardella, Matthew'],\n",
              " 'title': \"XML Developer's Guide\",\n",
              " 'genre': 'Computer',\n",
              " 'price': '44.95',\n",
              " 'publish_date': '2000-10-01',\n",
              " 'description': 'An in-depth look at creating applications with XML.'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si deseamos imprimir los títulos de todos los libros podemos hacer:"
      ],
      "metadata": {
        "id": "dVKsgW405qcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for libro in data['catalog']['book']:\n",
        "    print(libro['title'])"
      ],
      "metadata": {
        "id": "KwhdTfnp5w8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393e25e7-bc80-4f31-c9ad-d48b903b6c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XML Developer's Guide\n",
            "Midnight Rain\n",
            "Maeve Ascendant\n",
            "Oberon's Legacy\n",
            "The Sundered Grail\n",
            "Lover Birds\n",
            "Splish Splash\n",
            "Creepy Crawlies\n",
            "Paradox Lost\n",
            "Microsoft .NET: The Programming Bible\n",
            "MSXML3: A Comprehensive Guide\n",
            "Visual Studio 7: A Comprehensive Guide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-3IvYEkwEK_"
      },
      "source": [
        "**Ejemplo: uso de la API de NOAA.**\n",
        "\n",
        "La Oficina Nacional de Administración Oceánica y Atmosférica (National Oceanic and Atmospheric Administration, NOAA) es una agencia científica del Departamento de Comercio de los Estados Unidos cuyas actividades se centran en monitorear las condiciones de los océanos y la atmósfera.\n",
        "\n",
        "El NOAA ofrece distintos *datasets* (conjuntos de datos estructurados) sin limitaciones. Los datos puedes ser bajados directamente del sitio web https://www.noaa.gov/ o, alternativamente, accedidos por API.\n",
        "\n",
        "En esta sección accederemos a los datasets utilizando la API. Para utilizar la API se debe solicitar  un *token* al NOAA (en  https://www.ncdc.noaa.gov/cdo-web/token). El token es una cadena de caracteres que funciona como id y password al mismo tiempo.\n",
        "\n",
        "Si al comienzo ponemos\n",
        "\n",
        "    import requests\n",
        "    token = 'nuestro token'\n",
        "    my_headers = {'token' : token}\n",
        "    response = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/datasets', headers=my_headers)\n",
        "    respuesta = response.json()\n",
        "    resultados = respuesta['results'] # Datasets disponible\n",
        "    for w in resultados:\n",
        "      pass\n",
        "      print(w['uid'],':',w['name'])\n",
        "\n",
        "obtendremos el `id` de cada uno de los datasets ofrecidos por el NOAA via API y una breve descripción de los mismos. En particular,  son interesantes:\n",
        "\n",
        "    GHCND : Daily Summaries\n",
        "    GSOM : Global Summary of the Month\n",
        "    GSOY : Global Summary of the Year\n",
        "\n",
        "La API permite una variedad de consultas, por ejemplo\n",
        "\n",
        "    response = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/datasets?locationid=CITY:US390029', headers=my_headers)\n",
        "    respuesta = response.json()\n",
        "\n",
        "nos devuelve todos los datasets disponibles para determinada localidad.\n",
        "\n",
        "También podemos obtener, por ejemplo, datos climatológicos de una determinada localidad durante un período determinado de tiempo: la consulta\n",
        "\n",
        "    response = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&stationid=GHCND:AR000087344&units=metric&startdate=2021-05-01&enddate=2021-05-31', headers=my_headers)\n",
        "    respuesta = response.json()\n",
        "    resultados = respuesta['results']\n",
        "\n",
        "nos devuelve un sumario de temperaturas y precipitaciones diarias en el mes de mayo de la estación meteorológica del Aeropuerto de Córdoba.  \n",
        "\n",
        "En las referencias a continuación se encuentra como obtener el token, la descripción de la API, la lista de estaciones meteorológicas y mucha más información. Luego viene una celda de código con ejemplos.\n",
        "\n",
        "\n",
        "\n",
        "*Referencias*\n",
        "- https://www.ncdc.noaa.gov/ National Centers for Environmental Information (37 petabytes)\n",
        "- https://www.ncei.noaa.gov/support/access-data-service-api-user-documentation\n",
        "- Para bajar estaciones meteorolgógicas:  https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
        "- https://www.ncdc.noaa.gov/ghcn-daily-description\n",
        "- Para bajar manual de ghcn-daily: https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt\n",
        "- Para pedir token: https://www.ncdc.noaa.gov/cdo-web/token\n",
        "- Climate Data Online - Web Services Documentation: https://www.ncdc.noaa.gov/cdo-web/webservices/v2#gettingStarted\n",
        "- Manual genérico para uso de APIs en Python: https://www.nylas.com/blog/use-python-requests-module-rest-apis/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY53R0m7Il9E",
        "outputId": "5b4d0e32-16bb-4ec2-9a34-d8223fe1c06b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GHCND : Daily Summaries\n",
            "GSOM : Global Summary of the Month\n",
            "GSOY : Global Summary of the Year\n",
            "NEXRAD2 : Weather Radar (Level II)\n",
            "NEXRAD3 : Weather Radar (Level III)\n",
            "NORMAL_ANN : Normals Annual/Seasonal\n",
            "NORMAL_DLY : Normals Daily\n",
            "NORMAL_HLY : Normals Hourly\n",
            "NORMAL_MLY : Normals Monthly\n",
            "PRECIP_15 : Precipitation 15 Minute\n",
            "PRECIP_HLY : Precipitation Hourly\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "token = 'LsJXpYprYMzOKjMtqAlDmMUzwGelIQDf'\n",
        "my_headers = {'token' : token}\n",
        "# Ejemplo: datasets disponibles en NOAA\n",
        "response = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/datasets', headers=my_headers)\n",
        "respuesta = response.json()\n",
        "\n",
        "resultados = respuesta['results'] # Datasets disponibles\n",
        "\n",
        "for w in resultados:\n",
        "  pass\n",
        "  print(w['id'],':',w['name'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo: datasets  disponible en la ciudad US390029\n",
        "response = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/datasets?locationid=CITY:US390029', headers=my_headers)\n",
        "respuesta = response.json()\n",
        "print(respuesta)"
      ],
      "metadata": {
        "id": "FUM2qg7YfAIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b2501d-7191-48e0-b28f-b1b9d92038a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metadata': {'resultset': {'offset': 1, 'count': 10, 'limit': 25}}, 'results': [{'uid': 'gov.noaa.ncdc:C00861', 'mindate': '1763-01-01', 'maxdate': '2023-06-02', 'name': 'Daily Summaries', 'datacoverage': 1, 'id': 'GHCND'}, {'uid': 'gov.noaa.ncdc:C00946', 'mindate': '1763-01-01', 'maxdate': '2023-05-01', 'name': 'Global Summary of the Month', 'datacoverage': 1, 'id': 'GSOM'}, {'uid': 'gov.noaa.ncdc:C00947', 'mindate': '1763-01-01', 'maxdate': '2023-01-01', 'name': 'Global Summary of the Year', 'datacoverage': 1, 'id': 'GSOY'}, {'uid': 'gov.noaa.ncdc:C00345', 'mindate': '1991-06-05', 'maxdate': '2023-05-29', 'name': 'Weather Radar (Level II)', 'datacoverage': 0.95, 'id': 'NEXRAD2'}, {'uid': 'gov.noaa.ncdc:C00708', 'mindate': '1994-05-20', 'maxdate': '2023-05-30', 'name': 'Weather Radar (Level III)', 'datacoverage': 0.95, 'id': 'NEXRAD3'}, {'uid': 'gov.noaa.ncdc:C00821', 'mindate': '2010-01-01', 'maxdate': '2010-01-01', 'name': 'Normals Annual/Seasonal', 'datacoverage': 1, 'id': 'NORMAL_ANN'}, {'uid': 'gov.noaa.ncdc:C00823', 'mindate': '2010-01-01', 'maxdate': '2010-12-31', 'name': 'Normals Daily', 'datacoverage': 1, 'id': 'NORMAL_DLY'}, {'uid': 'gov.noaa.ncdc:C00822', 'mindate': '2010-01-01', 'maxdate': '2010-12-01', 'name': 'Normals Monthly', 'datacoverage': 1, 'id': 'NORMAL_MLY'}, {'uid': 'gov.noaa.ncdc:C00505', 'mindate': '1970-05-12', 'maxdate': '2014-01-01', 'name': 'Precipitation 15 Minute', 'datacoverage': 0.25, 'id': 'PRECIP_15'}, {'uid': 'gov.noaa.ncdc:C00313', 'mindate': '1900-01-01', 'maxdate': '2014-01-01', 'name': 'Precipitation Hourly', 'datacoverage': 1, 'id': 'PRECIP_HLY'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos climatológicos diarios (temperatura máxima, temperatura mínima y precipitaciones) en un período de tiempo en\n",
        "# la estación meteorológica  AR000087344 (Aeropuerto de Córdoba)\n",
        "fecha_ini, fecha_fin = '2022-06-02', '2022-06-03'\n",
        "response = requests.get('https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&stationid=GHCND:AR000087344&limit=1000&units=metric&startdate='+fecha_ini+'&enddate='+fecha_fin+'', headers=my_headers)\n",
        "print(response.status_code)\n",
        "respuesta = response.json()\n",
        "resultados = respuesta['results']\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "GjGoJbLafDX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b19855d-c3a6-4a7f-c42b-c08726bbd075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "{'metadata': {'resultset': {'offset': 1, 'count': 4, 'limit': 1000}}, 'results': [{'date': '2022-06-02T00:00:00', 'datatype': 'TAVG', 'station': 'GHCND:AR000087344', 'attributes': 'H,,S,', 'value': 8.6}, {'date': '2022-06-03T00:00:00', 'datatype': 'TAVG', 'station': 'GHCND:AR000087344', 'attributes': 'H,,S,', 'value': 8.3}, {'date': '2022-06-03T00:00:00', 'datatype': 'TMAX', 'station': 'GHCND:AR000087344', 'attributes': ',,S,', 'value': 16.0}, {'date': '2022-06-03T00:00:00', 'datatype': 'TMIN', 'station': 'GHCND:AR000087344', 'attributes': ',,S,', 'value': 3.5}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for w in resultados:\n",
        "  print(w)\n",
        "# Observación 1. Cuidado: no necesariamente todos los días tienen todos los datos.\n",
        "# Observación 2. Por defecto la API  recupera 25 registros por llamada. En la llamada anterior pusimos 'limit=1000'\n",
        "#                para recuperar hasta 1000 registros por llamada. La API no permite más."
      ],
      "metadata": {
        "id": "PnKwmTOufJPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fc9292-54b5-421a-cea0-e2a385b9739c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'date': '2022-06-02T00:00:00', 'datatype': 'TAVG', 'station': 'GHCND:AR000087344', 'attributes': 'H,,S,', 'value': 8.6}\n",
            "{'date': '2022-06-03T00:00:00', 'datatype': 'TAVG', 'station': 'GHCND:AR000087344', 'attributes': 'H,,S,', 'value': 8.3}\n",
            "{'date': '2022-06-03T00:00:00', 'datatype': 'TMAX', 'station': 'GHCND:AR000087344', 'attributes': ',,S,', 'value': 16.0}\n",
            "{'date': '2022-06-03T00:00:00', 'datatype': 'TMIN', 'station': 'GHCND:AR000087344', 'attributes': ',,S,', 'value': 3.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MmiuOvXw86d"
      },
      "source": [
        "Observar que cada elemento de  `resultados` es un diccionario y en ese diccionario  estan las claves`date`, `datatype` y `value`.\n",
        "- `date` indica el día.\n",
        "- Si el `datatype` es `TMAX`,  entonces `value` indica la temperatura máxima del día.\n",
        "- Si el `datatype` es `TMIN`,  entonces `value` indica la temperatura mínima del día.\n",
        "- Si el `datatype` es `TAVG`,  entonces `value` indica la temperatura promedio del día.\n",
        "- Si el `datatype` es `PRCP`,  entonces `value` indica la precipitación (en mm) de ese día."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por ejemplo, obtengamos la temperatura promedio máxima de la ciudad de Córdoba en el año 1998"
      ],
      "metadata": {
        "id": "RZ_OxNZPy5cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Lectura y escritura de archivos XML\n",
        "\n",
        "Un archivo XML (Extensible Markup Language) es un tipo de archivo de texto que se utiliza para almacenar y transportar datos de manera estructurada. Un archivo XML está compuesto por una serie de etiquetas que definen elementos y atributos que describen la estructura y los datos contenidos en el archivo.\n",
        "\n",
        "Cada elemento en un archivo XML está compuesto por una etiqueta de apertura y una etiqueta de cierre, y puede contener elementos anidados y atributos. Por ejemplo, el siguiente es un ejemplo simple de un archivo XML que contiene información sobre una persona:\n",
        "\n",
        "    <persona>\n",
        "    <nombre>Juan</nombre>\n",
        "    <edad>30</edad>\n",
        "    <ciudad>Córdoba</ciudad>\n",
        "    </persona>\n",
        "\n",
        "En este ejemplo, el elemento `persona` es el elemento raíz del archivo XML, y contiene tres elementos anidados: `nombre`, `edad` y `ciudad`. Cada uno de estos elementos tiene un valor asociado, que se encuentra entre las etiquetas de apertura y cierre.\n",
        "\n",
        "Los archivos XML se utilizan comúnmente para intercambiar datos entre diferentes sistemas o aplicaciones, ya que proporcionan una forma estructurada y legible por máquinas para representar la información. También se pueden utilizar para definir y describir documentos y aplicaciones complejas, como documentos de ayuda en línea, aplicaciones web y formatos de archivo personalizados.\n",
        "\n",
        "Esta estructura se puede implmentar en JSON también:\n",
        "\n",
        "\n",
        "    {'persona':  [{'nombre': 'Juan'}, {'edad': '30'}, {'ciudad': 'Córdoba'}]\n",
        "\n",
        "Obviamente hay otras formas de hacerlo.\n"
      ],
      "metadata": {
        "id": "dBj7xJd9NmGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Elementos y atributos\n",
        "En XML, los *elementos* son las partes principales de un documento XML y representan los distintos elementos de información que se están describiendo en el documento. Los elementos tienen un nombre que los identifica y pueden contener *otros elementos*, *atributos* o *texto*.\n",
        "\n",
        "Por ejemplo, en el siguiente fragmento de código XML, `<trkpt>` y `<ele>` son elementos:\n",
        "\n",
        "    <trkpt lat=\"-30.9424310\" lon=\"-64.2770290\">\n",
        "        <ele>740.7</ele>\n",
        "    </trkpt>\n",
        "\n",
        "Los *atributos*, por otro lado, proporcionan información adicional sobre los elementos y se utilizan para describir características específicas del elemento. Los atributos se incluyen dentro de la etiqueta del elemento y tienen un nombre y un valor.\n",
        "\n",
        "En el ejemplo anterior, `lat` y `lon` son atributos del elemento `<trkpt>`. El valor de los atributos se especifica entre comillas dobles después del nombre del atributo, separado por un signo igual.\n",
        "\n",
        "Los elementos y atributos en XML se utilizan para estructurar y describir los datos de forma clara y organizada. Los elementos proporcionan la estructura general del documento XML y los atributos permiten proporcionar información adicional sobre los elementos."
      ],
      "metadata": {
        "id": "_fhteHL6VFL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2. xml.dom\n",
        "\n",
        "La biblioteca `xml.dom` de Python es una biblioteca estándar que proporciona una forma de analizar y manipular documentos XML mediante el modelo de objetos del documento (DOM, por sus siglas en inglés). El modelo DOM representa el documento XML como un árbol de nodos, donde cada nodo representa un elemento, atributo, texto u otro tipo de contenido en el documento.\n",
        "\n",
        "Para obtener elementos y atributos de un documento XML utilizando la biblioteca xml.dom, puedes seguir estos pasos:\n",
        "\n",
        "Importar la biblioteca y abrir el archivo XML:\n",
        "\n",
        "    import xml.dom.minidom\n",
        "    # Abrir archivo XML\n",
        "    doc = xml.dom.minidom.parse(\"archivo.xml\")\n",
        "\n",
        "\n",
        "Si los datos vienen dados por una cadena, en vez de un archivo,  cambia un poco el código:\n",
        "\n",
        "    import xml.dom.minidom\n",
        "    # Abrir cadena XML\n",
        "    doc = xml.dom.minidom.parseString(xml_string)\n",
        "\n",
        "Obtener los elementos del documento mediante el método `getElementsByTagName`:\n",
        "\n",
        "    # Obtener elementos\n",
        "    elementos = doc.getElementsByTagName(\"nombre_del_elemento\")\n",
        "Obtener los atributos de un elemento mediante el método `getAttribute`:\n",
        "\n",
        "    # Obtener atributo\n",
        "    valor_atributo = elementos[0].getAttribute(\"nombre_del_atributo\")\n",
        "Obtener el contenido de un elemento mediante el método `firstChild.nodeValue`:\n",
        "\n",
        "    # Obtener contenido\n",
        "    contenido = elementos[0].firstChild.nodeValue\n",
        "En el ejemplo anterior, se utiliza `xml.dom.minidom` para parsear el archivo XML y convertirlo en un objeto `Document`. Luego, se utiliza el método `getElementsByTagName` para obtener todos los elementos del documento con un nombre de etiqueta específico. Una vez que se tienen los elementos, se pueden obtener sus atributos utilizando el método `getAttribute` y su contenido utilizando la propiedad `firstChild.nodeValue`.\n",
        "\n",
        "Es importante tener en cuenta que el método `getElementsByTagName` devuelve una lista de elementos, incluso si solo hay un elemento con el nombre de etiqueta especificado en el documento. Por lo tanto, en el ejemplo anterior se utiliza `elementos[0]` para acceder al primer elemento de la lista. Si se espera que solo haya un elemento con el nombre de etiqueta especificado en el documento, se puede utilizar `getElementsByTagName(nombre_del_elemento)[0]` para obtener directamente ese elemento."
      ],
      "metadata": {
        "id": "GrNvfT07UgvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3. Ejemplo\n",
        "Veamos ahora un archivo XML de internet,  con una estructura no demasiado complicada pero con más registros. El archivo que vamos a leer es `books.xml` y su estrucura es:\n",
        "\n",
        "    <?xml version=\"1.0\"?>\n",
        "    <catalog>\n",
        "    <book id=\"bk101\">\n",
        "        <author>Gambardella, Matthew</author>\n",
        "        <title>XML Developer's Guide</title>\n",
        "        <genre>Computer</genre>\n",
        "        <price>44.95</price>\n",
        "        <publish_date>2000-10-01</publish_date>\n",
        "        <description>An in-depth look at creating applications\n",
        "        with XML.</description>\n",
        "    </book>\n",
        "    <book id=\"bk102\">\n",
        "        <author>Ralls, Kim</author>\n",
        "        <author>Gambardella, Matthew</author>\n",
        "        <title>Midnight Rain</title>\n",
        "        <genre>Fantasy</genre>\n",
        "        <price>5.95</price>\n",
        "        <publish_date>2000-12-16</publish_date>\n",
        "        <description>A former architect battles corporate zombies,\n",
        "        an evil sorceress, and her own childhood to become queen\n",
        "        of the world.</description>\n",
        "    </book>\n",
        "        ...\n",
        "        ...\n",
        "    </catalog>\n",
        "\n",
        "Es decir, es un catálogo de libros y  cada libro contiene información sobre el título,  su autor o autores,  etc. Observar que este archivo no puede ser representado en formato CSV, pues el elemento `author`se puede repetir un número indeterminado de veces.\n",
        "\n",
        "La ubicación del archivo es\n",
        "\n",
        "    https://raw.githubusercontent.com/tirabo/Algoritmos-y-Programacion/main/2023/archivos/books.xml"
      ],
      "metadata": {
        "id": "Y3rY6K00SRmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "respuesta = requests.get('https://raw.githubusercontent.com/tirabo/Algoritmos-y-Programacion/main/2023/archivos/books.xml')\n",
        "xml_string = respuesta.content\n",
        "respuesta.status_code"
      ],
      "metadata": {
        "id": "wKwxox4cQ611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06b6717-9ad2-4f5f-8940-35d78b7d9170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`200` nos indica que el archivo ha sido leido sin inconvenientes.\n",
        "\n",
        "Ahora procederemos a \"parsear\"  el archivo (que es un XML), usando las instrucciones que vimos más arriba:"
      ],
      "metadata": {
        "id": "hw5eZuVtYCcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.dom.minidom\n",
        "# Abrir cadena XML\n",
        "dom = xml.dom.minidom.parseString(xml_string) # cuando viene dado por una cadena\n",
        "print('tipo  de dom:', type(dom))\n",
        "# Obtener elementos\n",
        "elementos = dom.getElementsByTagName(\"book\")\n",
        "print('El  primer elemento book:',elementos[0])\n",
        "print('El  segundo elemento book:',elementos[1])\n",
        "# Obtener atributo\n",
        "valor_atributo = elementos[0].getAttribute(\"id\")\n",
        "print('Atributo \\'id\\' del primer elemento \\'book\\':', valor_atributo)\n",
        "valor_atributo_1 = elementos[1].getAttribute(\"id\")\n",
        "print('Atributo \\'id\\' del segundo elemento \\'book\\':', valor_atributo_1)\n",
        "\n",
        "# Obtener contenido\n",
        "contenido = elementos[0].firstChild.nodeValue\n",
        "print(type(contenido),':', contenido) # no hay contenido de texto\n",
        "autor = elementos[0].getElementsByTagName(\"author\")\n",
        "contenido = autor[0].firstChild.nodeValue\n",
        "print('El primer autor del primer libro es:', type(contenido),':', contenido)\n"
      ],
      "metadata": {
        "id": "CDAA8vqmYZVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3064bbdc-ba97-47e3-b9c7-1f1adecb05ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tipo  de dom: <class 'xml.dom.minidom.Document'>\n",
            "El  primer elemento book: <DOM Element: book at 0x7fbfff179900>\n",
            "El  segundo elemento book: <DOM Element: book at 0x7fbfff179cf0>\n",
            "Atributo 'id' del primer elemento 'book': bk101\n",
            "Atributo 'id' del segundo elemento 'book': bk102\n",
            "<class 'str'> : \n",
            "      \n",
            "El primer autor del primer libro es: <class 'str'> : Gambardella, Matthew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observar que el segundo libro tiene dos autores, por lo tanto para recuperar todos los autores por cada `id` podemos hacer:"
      ],
      "metadata": {
        "id": "A518X73tb7pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "libros = []\n",
        "for elemento in elementos:\n",
        "    id_libro = elemento.getAttribute(\"id\")\n",
        "    autores_obj = elemento.getElementsByTagName(\"author\")\n",
        "    autores = []\n",
        "    for autor in autores_obj:\n",
        "        autores.append(autor.firstChild.nodeValue)\n",
        "    libros.append((id_libro,  autores))\n",
        "\n",
        "for libro in libros:\n",
        "    print(libro)\n"
      ],
      "metadata": {
        "id": "Co8-xspicIrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323c0eaf-cfcd-491b-b7e8-9f44b342cfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('bk101', ['Gambardella, Matthew'])\n",
            "('bk102', ['Ralls, Kim', 'Gambardella, Matthew'])\n",
            "('bk103', ['Corets, Eva'])\n",
            "('bk104', ['Corets, Eva'])\n",
            "('bk105', ['Corets, Eva'])\n",
            "('bk106', ['Randall, Cynthia'])\n",
            "('bk107', ['Thurman, Paula'])\n",
            "('bk108', ['Knorr, Stefan'])\n",
            "('bk109', ['Kress, Peter'])\n",
            "('bk110', [\"O'Brien, Tim\"])\n",
            "('bk111', [\"O'Brien, Tim\"])\n",
            "('bk112', ['Galos, Mike'])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "df45a1d593e760cb2f2d0116876d0d9854c557dc207c92c5b1e029045d5f17a5"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}